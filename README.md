# ðŸ“š Scrapy Books â€“ Web Scraping Project with Scrapy

This project is a practical implementation of web scraping using [Scrapy](https://scrapy.org/), based on the [freeCodeCamp.org Scrapy course](https://www.youtube.com/watch?v=QblMHLvQalo) by Joe Kearney.

The goal of this project is to crawl book data from an online website and extract structured information such as titles, prices, availability, ratings, and more. This repo includes features like item pipelines, CSV export, and best practices for robust scraping.

---

## ðŸš€ Features

- Crawl and extract data from multiple pages
- Clean and structure data using Scrapy Items and Pipelines
- Export data to CSV
- Handle fake headers and user-agents
- Rotating proxies (optional)
- Scalable architecture ready for deployment to the cloud

---

## ðŸ•¸ Example Data Extracted

- Book Title
- Price
- Rating
- Availability
- Product Page Link

---

## ðŸ“‚ Project Structure

```bash
scrapy_books/
â”œâ”€â”€ scrapy_books/          # Scrapy project core
â”‚   â”œâ”€â”€ __init__.py
â”‚   â”œâ”€â”€ items.py           # Define scraped data structure
â”‚   â”œâ”€â”€ middlewares.py
â”‚   â”œâ”€â”€ pipelines.py       # Process and clean scraped data
â”‚   â”œâ”€â”€ settings.py        # Scrapy project settings
â”‚   â””â”€â”€ spiders/           # Spiders directory
â”‚       â””â”€â”€ books_spider.py  # Main spider
â”œâ”€â”€ output.csv             # Exported data (if saved as CSV)
â”œâ”€â”€ README.md              # This file
